{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Cornell Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers, layers, losses, preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from helper_fxns import remove_url, clean_text\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import string\n",
    "import nltk\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0Metal device set to: Apple M1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 23:25:15.699859: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-28 23:25:15.700261: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-10-28 23:25:15.701613: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-28 23:25:15.701621: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "  print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "  print('Please install GPU version of TF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the Cornell Dataset into DataFrames\n",
    "\n",
    "The codes in this subsection only needs to be run once, as the data has already been combined into 1 csv file and is saved. Hence, the next time round, this section can just be skipped and the .csv file can just be loaded in directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(tag):\n",
    "    DIR = os.path.join(\"review_polarity/txt_sentoken/\", tag)\n",
    "    contents = os.listdir(DIR)\n",
    "\n",
    "    text = []\n",
    "\n",
    "    if \".DS_Store\" in contents:\n",
    "        contents.remove(\".DS_Store\")\n",
    "\n",
    "    for file in contents:\n",
    "        file_path = os.path.join(DIR, file)\n",
    "        with open(file_path) as f:\n",
    "            lines = f.read()\n",
    "        lines = lines.replace(\"\\n\", \" \")\n",
    "        text.append(lines)\n",
    "    \n",
    "    num_texts = len(contents)\n",
    "    label = [tag] * num_texts\n",
    "\n",
    "    if len(text) == len(label):\n",
    "        print(\"INFO: Correct Length of Text and Label!\")\n",
    "    else:\n",
    "        print(f\"ERROR: Mismatch of Lengths Text : {len(text)}, Label : {len(label)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    data_dict = {\"text\" : text, \"sentiment\" : label}\n",
    "\n",
    "    data_df = pd.DataFrame(data_dict)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Correct Length of Text and Label!\n",
      "INFO: Correct Length of Text and Label!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing .  the phrase is perhaps one of...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot : derek zoolander is a male model .  he i...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original 1961 or so...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie that's been as highly built up as the ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" good will hunting \" is two movies in one : ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  assume nothing .  the phrase is perhaps one of...       pos\n",
       "1  plot : derek zoolander is a male model .  he i...       pos\n",
       "2  i actually am a fan of the original 1961 or so...       pos\n",
       "3  a movie that's been as highly built up as the ...       pos\n",
       "4   \" good will hunting \" is two movies in one : ...       pos"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df = create_df('pos')\n",
    "neg_df = create_df('neg')\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .  bad .  that one word seems to pre...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isn't it the ultimate sign of a movie's cinema...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" gordy \" is not a movie , it is a 90-minute-...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disconnect the phone line .  don't accept the ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when robert forster found himself famous again...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  bad . bad .  bad .  that one word seems to pre...       neg\n",
       "1  isn't it the ultimate sign of a movie's cinema...       neg\n",
       "2   \" gordy \" is not a movie , it is a 90-minute-...       neg\n",
       "3  disconnect the phone line .  don't accept the ...       neg\n",
       "4  when robert forster found himself famous again...       neg"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing .  the phrase is perhaps one of...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot : derek zoolander is a male model .  he i...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i actually am a fan of the original 1961 or so...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a movie that's been as highly built up as the ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" good will hunting \" is two movies in one : ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>synopsis : when a meteorite crashlands in the ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>it's now the anniversary of the slayings of ju...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>coinciding with the emerging popularity of mov...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>and now the high-flying hong kong style of fil...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>battlefield long , boring and just plain stupi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     assume nothing .  the phrase is perhaps one of...       pos\n",
       "1     plot : derek zoolander is a male model .  he i...       pos\n",
       "2     i actually am a fan of the original 1961 or so...       pos\n",
       "3     a movie that's been as highly built up as the ...       pos\n",
       "4      \" good will hunting \" is two movies in one : ...       pos\n",
       "...                                                 ...       ...\n",
       "1995  synopsis : when a meteorite crashlands in the ...       neg\n",
       "1996  it's now the anniversary of the slayings of ju...       neg\n",
       "1997  coinciding with the emerging popularity of mov...       neg\n",
       "1998  and now the high-flying hong kong style of fil...       neg\n",
       "1999  battlefield long , boring and just plain stupi...       neg\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the DataFrame into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cornell_polarity_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions to Remove URL and Clean Text\n",
    "\n",
    "Importing the remove_url and clean_text fucntions to remove any URL in the text and to remove punctuations in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume nothing the phrase perhaps one the most...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plot derek zoolander male model also very dumb...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actually fan the original liveactiondisney fli...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie thats been highly built the truman show ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good will hunting two movies one independent t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  assume nothing the phrase perhaps one the most...       pos\n",
       "1  plot derek zoolander male model also very dumb...       pos\n",
       "2  actually fan the original liveactiondisney fli...       pos\n",
       "3  movie thats been highly built the truman show ...       pos\n",
       "4  good will hunting two movies one independent t...       pos"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(remove_url)\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts in each of the Classes: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pos    1000\n",
       "neg    1000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of texts in each of the Classes: \")\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the value counts, we can see that the dataset is balanced and there is an equal distribution between Positive and Negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Updates a list on vocabulary based on the text. It kind of creates its Vocabulary. This is important before converting texts into sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into (train+val), test\n",
    "num_words = 1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words,oov_token=\"unk\")\n",
    "tokenizer.fit_on_texts(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training Sets into Different Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 2000\n",
      "Length of Train: 1600\n",
      "Length of Valid: 400\n"
     ]
    }
   ],
   "source": [
    "#Prior to splitting\n",
    "print(f\"Length of dataset: {len(df)}\")\n",
    "print(f\"Length of Train: {int(0.8 * len(df))}\")\n",
    "print(f\"Length of Valid: {int(0.2 * len(df))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test set, we will use the dataset.csv file, which can be loaded in after the training of this model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and validation data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df['text'].tolist(), \n",
    "                                                  df['sentiment'].tolist(), \n",
    "                                                  test_size=0.2, stratify=df['sentiment'].tolist(),\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train : 1600\n",
      "Length of Valid : 400\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Train : {len(X_train)}\")\n",
    "print(f\"Length of Valid : {len(X_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distributions:\n",
      "Train: Counter({'neg': 800, 'pos': 800})\n",
      "Valid: Counter({'neg': 200, 'pos': 200})\n"
     ]
    }
   ],
   "source": [
    "#getting the class distribution\n",
    "print(\"Class Distributions:\")\n",
    "print(f\"Train: {str(Counter(y_train))}\")\n",
    "print(f\"Valid: {str(Counter(y_valid))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Texts to Sequences and Storing them in Arrays\n",
    "\n",
    "Assigning an index to each word in the text sample. Do note that for the Tokenization, 0 is not assigned to any word, it is instead assigned to any new/unknown word that is not present in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/f2chvxk17fd0vhl03xl62d_80000gn/T/ipykernel_27681/719861227.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
      "/var/folders/54/f2chvxk17fd0vhl03xl62d_80000gn/T/ipykernel_27681/719861227.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_valid = np.array(tokenizer.texts_to_sequences(X_valid))\n"
     ]
    }
   ],
   "source": [
    "#Converts the texts to sequences and stores it in an array\n",
    "x_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
    "x_valid = np.array(tokenizer.texts_to_sequences(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Longest Word Sequence\n",
    "\n",
    "This is important as this kind of defines what the shape of the input should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words in the Longest Sentence in Train :  1512\n",
      "Number of Words in the Longest Sentence in Valid :  1880\n"
     ]
    }
   ],
   "source": [
    "#finding the longest word sequence\n",
    "train_num_words_text = pd.DataFrame(X_train, columns=['text'])['text'].apply(lambda x:len(str(x).split()))\n",
    "max_len_train = max(train_num_words_text)\n",
    "\n",
    "valid_num_words_text = pd.DataFrame(X_valid, columns=['ext'])['text'].apply(lambda x:len(str(x).split()))\n",
    "max_len_valid = max(valid_num_words_text)\n",
    "\n",
    "test_num_words_text = pd.DataFrame(X_test, columns=['Text'])['Text'].apply(lambda x:len(str(x).split()))\n",
    "max_len_test = max(test_num_words_text)\n",
    "\n",
    "print('Longest Sentence in terms of words in Train: ', max_len_train)\n",
    "print('Longest Sentence in terms of words in Valid: ', max_len_valid)\n",
    "print('Longest Sentence in terms of words in Test: ', max_len_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in order to account for the both Trian and the Valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fd9d67d0e9a41140145a4f72bf435aeee9c17c765bd40006482f4c6ff739f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
